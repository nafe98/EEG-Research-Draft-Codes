{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1f0d6f8",
   "metadata": {},
   "source": [
    "# About Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0c6b16",
   "metadata": {},
   "source": [
    "The dataset contains EEG signals from 11 subjects with labels of alert and drowsy. It can be opened with Matlab. We extracted the data for our own research purpose from another public dataset:\n",
    "\n",
    "Cao, Z., et al., Multi-channel EEG recordings during a sustained-attention driving task. Scientific data, 2019. 6(1): p. 1-8.\n",
    "\n",
    "If you find the dataset useful, please give credits to their works.\n",
    "\n",
    "The details on how the data were extracted are described in our paper:\n",
    "\n",
    "\"Jian Cui, Zirui Lan, Yisi Liu, Ruilin Li, Fan Li, Olga Sourina, Wolfgang MÃ¼ller-Wittig, A Compact and Interpretable Convolutional Neural Network for Cross-Subject Driver Drowsiness Detection from Single-Channel EEG, Methods, 2021, ISSN 1046-2023, https://doi.org/10.1016/j.ymeth.2021.04.017.\"\n",
    "\n",
    "The codes of the paper above are accessible from:\n",
    "\n",
    "https://github.com/cuijiancorbin/A-Compact-and-Interpretable-Convolutional-Neural-Network-for-Single-Channel-EEG\n",
    "\n",
    "The data file contains 3 variables and they are EEGsample, substate and subindex.\n",
    "\n",
    "\"EEGsample\" contains 2022 EEG samples of size 20x384 from 11 subjects. Each sample is a 3s EEG data with 128Hz from 30 EEG channels.\n",
    "\"subindex\" is an array of 2022x1. It contains the subject indexes from 1-11 corresponding to each EEG sample.\n",
    "\"substate\" is an array of 2022x1. It contains the labels of the samples. 0 corresponds to the alert state and 1 correspond to the drowsy state.\n",
    "\n",
    "The unbalanced version of this dataset is accessible from:\n",
    "https://figshare.com/articles/dataset/EEG_driver_drowsiness_dataset_unbalanced_/16586957"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac6f357",
   "metadata": {},
   "source": [
    "# Importing Libraires "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353c3577",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69622bfa",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e133b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "# Load the data from the provided .mat file\n",
    "file_path = 'EEG driver drowsiness dataset.mat'\n",
    "mat_data = scipy.io.loadmat(file_path)\n",
    "\n",
    "# Inspecting the keys and structure of the loaded data\n",
    "mat_data.keys(), {key: type(mat_data[key]) for key in mat_data.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ad68f7",
   "metadata": {},
   "source": [
    "# Inspecting the shape and content of the EEGsample, subindex, and substate arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2a428d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting the shape and content of the EEGsample, subindex, and substate arrays\n",
    "eeg_sample_shape = mat_data['EEGsample'].shape\n",
    "subindex_shape = mat_data['subindex'].shape\n",
    "substate_shape = mat_data['substate'].shape\n",
    "\n",
    "eeg_sample_shape, subindex_shape, substate_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f719b56c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(mat_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca9495a",
   "metadata": {},
   "source": [
    "#### The initial exploration of the EEG dataset reveals the following details:\n",
    "\n",
    "#### EEG Samples (EEGsample):\n",
    "\n",
    "  * The dataset contains 2022 EEG samples.\n",
    "  * Each EEG sample is from 30 channels.\n",
    "  * Each channel has 384 data points, corresponding to a 3-second EEG recording at a sampling rate of 128Hz.\n",
    "\n",
    "#### Subject States (substate):\n",
    "\n",
    "  * There are two unique states: 0 representing the alert state and 1 representing the drowsy state.\n",
    "  * Each state has 1011 samples, indicating a balanced dataset with respect to the two states.\n",
    "\n",
    "#### Subject Indexes (subindex):\n",
    "\n",
    "  * There are 11 unique subjects in the dataset (labeled 1 to 11).\n",
    "  * The distribution of samples across subjects varies, ranging from a minimum of 102 samples to a maximum of 314 samples per subject."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7d7423",
   "metadata": {},
   "source": [
    "# Analyzing EEG Data: Determining Sample Shape, Channel Count, and Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7c8dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the EEG data and other relevant information\n",
    "data = mat_data\n",
    "eeg_samples = data['EEGsample']\n",
    "subindex = data['subindex']\n",
    "substate = data['substate']\n",
    "\n",
    "\n",
    "num_samples, num_channels, num_time_points = eeg_sample_shape\n",
    "subject_indexes = mat_data['subindex'].flatten()\n",
    "labels = mat_data['substate'].flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64f613d",
   "metadata": {},
   "source": [
    "# Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ea56d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = np.isnan(eeg_samples).sum()\n",
    "if missing_values == 0:\n",
    "    print(\"No missing values in the EEG data.\")\n",
    "else:\n",
    "    print(\"Number of missing values:\", missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819488c9",
   "metadata": {},
   "source": [
    "### Calculate the duration of each sample in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841f30bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the duration of each sample in seconds\n",
    "sampling_rate = 128  # Hz\n",
    "sample_duration = num_time_points / sampling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c52a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of subjects:\", len(np.unique(subject_indexes)))\n",
    "print(\"EEGsample shape:\", eeg_sample_shape)\n",
    "print(\"Number of Samples:\", num_samples)\n",
    "print(\"Number of Channels:\", num_channels)\n",
    "print(\"Number of Time Points:\", num_time_points)\n",
    "print(\"Sample Duration (seconds):\", sample_duration)\n",
    "\n",
    "unique_labels, label_counts = np.unique(labels, return_counts=True)\n",
    "print(\"Unique labels:\", unique_labels)\n",
    "print(\"Label counts:\", label_counts) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f287aefa",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9894c634",
   "metadata": {},
   "source": [
    "## Distribution of Subindex and Substate Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f09e102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique values and their counts for subindex and substate\n",
    "unique_subindex, counts_subindex = np.unique(mat_data['subindex'], return_counts=True)\n",
    "unique_substate, counts_substate = np.unique(mat_data['substate'], return_counts=True)\n",
    "\n",
    "# Set up subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Plot histogram for subindex\n",
    "axes[0].bar(unique_subindex, counts_subindex, align='center', alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[0].set_title('Frequency of Subindex Values')\n",
    "axes[0].set_xlabel('Subindex Values')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add count annotations on top of the bars for subindex\n",
    "for x, y in zip(unique_subindex, counts_subindex):\n",
    "    axes[0].text(x, y + 0.1, str(y), ha='center', va='bottom')\n",
    "\n",
    "# Plot histogram for substate\n",
    "axes[1].bar(unique_substate, counts_substate, align='center', alpha=0.7, color='lightcoral', edgecolor='black')\n",
    "axes[1].set_title('Frequency of Substate Values')\n",
    "axes[1].set_xlabel('Substate Values')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add count annotations on top of the bars for substate\n",
    "for x, y in zip(unique_substate, counts_substate):\n",
    "    axes[1].text(x, y + 0.1, str(y), ha='center', va='bottom')\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a5a247",
   "metadata": {},
   "source": [
    "## Analysis of Substate Distribution Across Subindices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dbcd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by subindex and count occurrences of 0 and 1 in substate\n",
    "subindex_values, substate_counts = np.unique(mat_data['subindex'], return_counts=True)\n",
    "substate_0_counts = []\n",
    "substate_1_counts = []\n",
    "\n",
    "for subindex_value in subindex_values:\n",
    "    substate_values_for_subindex = mat_data['substate'][mat_data['subindex'] == subindex_value]\n",
    "    substate_0_counts.append(np.sum(substate_values_for_subindex == 0))\n",
    "    substate_1_counts.append(np.sum(substate_values_for_subindex == 1))\n",
    "\n",
    "# Set up the bar chart\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "bar_width = 0.35\n",
    "bar_positions_0 = np.arange(len(subindex_values))\n",
    "bar_positions_1 = bar_positions_0 + bar_width\n",
    "\n",
    "ax.bar(bar_positions_0, substate_0_counts, width=bar_width, label='Substate 0', alpha=0.7, color='skyblue', edgecolor='black')\n",
    "ax.bar(bar_positions_1, substate_1_counts, width=bar_width, label='Substate 1', alpha=0.7, color='lightcoral', edgecolor='black')\n",
    "\n",
    "# Add count annotations on top of each bar\n",
    "for x, y in zip(bar_positions_0, substate_0_counts):\n",
    "    ax.text(x, y + 0.1, str(y), ha='center', va='bottom')\n",
    "\n",
    "for x, y in zip(bar_positions_1, substate_1_counts):\n",
    "    ax.text(x, y + 0.1, str(y), ha='center', va='bottom')\n",
    "\n",
    "ax.set_xticks(bar_positions_0 + bar_width / 2)\n",
    "ax.set_xticklabels(subindex_values)\n",
    "ax.set_xlabel('Subindex Values')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Frequency of Substate Values for Each Subindex')\n",
    "ax.legend()\n",
    "ax.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d357b53",
   "metadata": {},
   "source": [
    "# Basic Statistical Overview of the EEG data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def2d7c5",
   "metadata": {},
   "source": [
    "## State-specific Analysis: Mean and Standard Deviation of EEG Channels for 'Alert' and 'Drowsy' States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534d3fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting individual components from the dataset\n",
    "EEGsamples = data['EEGsample']\n",
    "substates = data['substate'].ravel()  # Flatten the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957ddb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating means and standard deviations for each channel in both states\n",
    "\n",
    "#Alert States\n",
    "mean_alert = np.mean(EEGsamples[substates == 0], axis=(0, 2))\n",
    "std_alert = np.std(EEGsamples[substates == 0], axis=(0, 2))\n",
    "\n",
    "#Drowsy States\n",
    "mean_drowsy = np.mean(EEGsamples[substates == 1], axis=(0, 2))\n",
    "std_drowsy = np.std(EEGsamples[substates == 1], axis=(0, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bd1ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DataFrame for easy viewing\n",
    "stats_df = pd.DataFrame({\n",
    "    'Channel': range(1, 31),\n",
    "    'Mean_Alert': mean_alert,\n",
    "    'Std_Alert': std_alert,\n",
    "    'Mean_Drowsy': mean_drowsy,\n",
    "    'Std_Drowsy': std_drowsy\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83646eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff72d804",
   "metadata": {},
   "source": [
    "## EEG Channel Statistics Across Subjects and Timepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e5d3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute basic statistics for each EEG channel\n",
    "mean_values = np.mean(eeg_samples, axis=(0, 2))  # Compute mean along subjects and timepoints\n",
    "std_values = np.std(eeg_samples, axis=(0, 2))    # Compute standard deviation along subjects and timepoints\n",
    "min_values = np.min(eeg_samples, axis=(0, 2))    # Compute minimum along subjects and timepoints\n",
    "max_values = np.max(eeg_samples, axis=(0, 2))    # Compute maximum along subjects and timepoints\n",
    "\n",
    "# Display basic statistics for each EEG channel\n",
    "for channel_index in range(num_channels):\n",
    "    print(\"Channel {}: Mean: {:.4f}, Std: {:.4f}, Min: {:.4f}, Max: {:.4f}\".format(\n",
    "        channel_index + 1, mean_values[channel_index], std_values[channel_index],\n",
    "        min_values[channel_index], max_values[channel_index]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3894cce",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eda7e120",
   "metadata": {},
   "source": [
    "For the preprocessing stage of EEG data analysis, we'll focus on three main aspects: noise reduction, artifact removal, and normalization. Here's the plan:\n",
    "\n",
    "Noise Reduction:\n",
    "\n",
    "Apply a bandpass filter to remove frequencies outside the typical brainwave range (1-50 Hz). This step helps in reducing high-frequency noise and very low-frequency drifts.\n",
    "Artifact Removal:\n",
    "\n",
    "Implement a technique to detect and remove artifacts caused by eye movements or muscle activities. Independent Component Analysis (ICA) is commonly used for this purpose. However, since ICA is computationally intensive and requires careful interpretation, a simpler approach might be to identify and exclude epochs with unusually high amplitude variations.\n",
    "Normalization:\n",
    "\n",
    "Normalize the EEG data across channels to ensure consistent amplitude ranges. This step is crucial for comparing data across different subjects and sessions.\n",
    "Let's start with the noise reduction step. We'll apply a bandpass filter to the EEG data. This will be followed by a simple artifact removal technique, where we identify and potentially exclude epochs with unusually high amplitude variations. Finally, we will normalize the EEG data.\n",
    "\n",
    "The preprocessing of the EEG dataset has been completed with the following steps:\n",
    "\n",
    "Noise Reduction:\n",
    "\n",
    "Applied a bandpass filter with a range of 1-50 Hz to all EEG samples. This filter helps in reducing high-frequency noise and low-frequency drifts.\n",
    "Artifact Removal:\n",
    "\n",
    "Detected artifacts using a simple amplitude threshold approach. A total of 173 samples were identified as having potential artifacts due to excessive amplitude variations. For more sophisticated analyses, techniques like Independent Component Analysis (ICA) can be employed, but this requires careful interpretation and is computationally intensive.\n",
    "Normalization:\n",
    "\n",
    "Normalized the EEG data across channels to ensure consistent amplitude ranges. This normalization is crucial for allowing comparisons across different subjects and sessions.\n",
    "Data Shapes After Preprocessing:\n",
    "Filtered Data Shape: Maintained at 2022 samples, each with 30 channels and 384 data points.\n",
    "Artifacts Detected: 173 out of 2022 samples were flagged for potential artifacts.\n",
    "Normalized Data Shape: Same as the filtered data, indicating that normalization was applied to each sample uniformly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098b01c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'EEG driver drowsiness dataset.mat'\n",
    "data = scipy.io.loadmat(file_path)\n",
    "\n",
    "# Extract the relevant variables\n",
    "EEGsample = data['EEGsample']\n",
    "substate = data['substate']\n",
    "subindex = data['subindex']\n",
    "\n",
    "# Initial data exploration\n",
    "EEGsample_shape = EEGsample.shape\n",
    "substate_unique, substate_counts = np.unique(substate, return_counts=True)\n",
    "subindex_unique, subindex_counts = np.unique(subindex, return_counts=True)\n",
    "\n",
    "EEGsample_shape, substate_unique, substate_counts, subindex_unique, subindex_counts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdb4f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import butter, filtfilt\n",
    "\n",
    "# Function to apply a bandpass filter\n",
    "def bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    nyquist = 0.5 * fs\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    filtered_data = filtfilt(b, a, data, axis=2)\n",
    "    return filtered_data\n",
    "\n",
    "# Apply the bandpass filter (1-50 Hz) to the EEG data\n",
    "fs = 128  # Sampling rate\n",
    "lowcut = 1.0  # Low frequency limit\n",
    "highcut = 50.0  # High frequency limit\n",
    "EEGsample_filtered = bandpass_filter(EEGsample, lowcut, highcut, fs)\n",
    "\n",
    "# Artifact Removal: Identify and mark samples with excessive amplitude\n",
    "# (Defining a simple threshold based approach)\n",
    "amplitude_threshold = 100  # Threshold for identifying artifacts, needs tuning based on the data\n",
    "artifact_mask = np.max(np.abs(EEGsample_filtered), axis=(1, 2)) > amplitude_threshold\n",
    "\n",
    "# Normalize the EEG data\n",
    "EEGsample_normalized = EEGsample_filtered / np.max(np.abs(EEGsample_filtered))\n",
    "\n",
    "# Summarizing the preprocessing steps\n",
    "preprocessing_summary = {\n",
    "    \"Filtered_Data_Shape\": EEGsample_filtered.shape,\n",
    "    \"Artifacts_Detected\": np.sum(artifact_mask),\n",
    "    \"Normalized_Data_Shape\": EEGsample_normalized.shape\n",
    "}\n",
    "\n",
    "preprocessing_summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3af0aab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ef91b70",
   "metadata": {},
   "source": [
    "#  Feature extraction"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0ab22708",
   "metadata": {},
   "source": [
    "For feature extraction from the EEG data, we'll focus on extracting meaningful features from three domains: time-domain, frequency-domain, and time-frequency domain. These features will be crucial for the subsequent analysis and machine learning modeling. Here's the plan:\n",
    "\n",
    "Time-Domain Features:\n",
    "\n",
    "Statistical Features: Mean, standard deviation, skewness, kurtosis of the EEG signal amplitude.\n",
    "Hjorth Parameters: Activity, mobility, and complexity, which provide information about the signal's variance, frequency, and frequency variance.\n",
    "Frequency-Domain Features:\n",
    "\n",
    "Power Spectral Density (PSD): Use Fast Fourier Transform (FFT) to calculate PSD, which shows the power distribution over frequency bands (Delta, Theta, Alpha, Beta).\n",
    "Band Power Ratios: Calculate the ratios of power in different frequency bands (e.g., Alpha/Beta), which are indicative of different states of alertness or drowsiness.\n",
    "Time-Frequency Domain Features:\n",
    "\n",
    "Wavelet Transform: Apply Wavelet Transform to capture both time and frequency information. Extract features like wavelet energy and entropy.\n",
    "I'll start with the extraction of time-domain features, followed by frequency-domain and then time-frequency domain features. Let's begin with the time-domain features.\n",
    "\n",
    "The time-domain feature extraction for the EEG data has been completed with the following features:\n",
    "\n",
    "Statistical Features:\n",
    "\n",
    "Mean Values: Calculated for each of the 30 channels across all 2022 samples.\n",
    "Standard Deviation: Computed for each channel in all samples.\n",
    "Skewness: Measures the asymmetry of the EEG signal distribution.\n",
    "Kurtosis: Indicates the 'tailedness' of the EEG signal distribution.\n",
    "Hjorth Parameters:\n",
    "\n",
    "Activity: Represents the signal variance.\n",
    "Mobility: Measures the mean frequency or the rate of change in the signal.\n",
    "Complexity: Describes the bandwidth of the signal.\n",
    "Shapes of Extracted Features:\n",
    "Each feature has a shape of (2022 samples, 30 channels), corresponding to the 2022 EEG samples and 30 EEG channels.\n",
    "\n",
    "Next Steps:\n",
    "Now, we'll move on to the frequency-domain feature extraction. This will involve computing the Power Spectral Density (PSD) and band power ratios, which are crucial for understanding the power distribution across different frequency bands. These bands (Delta, Theta, Alpha, Beta) are often associated with different brain states, such as alertness and drowsiness.\n",
    "\n",
    "Let's proceed with the frequency-domain feature extraction. ââ\n",
    "\n",
    "The frequency-domain feature extraction for the EEG data has been successfully conducted, yielding the following features:\n",
    "\n",
    "Band Power for Different Frequency Bands:\n",
    "\n",
    "Delta Band Power (1-4 Hz): Associated with deep sleep or unconsciousness.\n",
    "Theta Band Power (4-8 Hz): Linked to drowsiness, relaxation, and reduced consciousness.\n",
    "Alpha Band Power (8-12 Hz): Typically related to relaxed and reflective states.\n",
    "Beta Band Power (12-30 Hz): Generally associated with active, busy, or anxious thinking and active concentration.\n",
    "Power Spectral Density (PSD):\n",
    "\n",
    "The PSD has been calculated for each of the 30 channels across all 2022 samples, with a frequency resolution provided by the Welch's method.\n",
    "Shapes of Extracted Features:\n",
    "Each band power feature has a shape of (2022 samples, 30 channels), aligning with the structure of the EEG dataset.\n",
    "The PSD shape is (2022 samples, 30 channels, 129 frequency bins), providing a comprehensive frequency breakdown for each sample and channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbdd6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "# Function to calculate Hjorth parameters\n",
    "def hjorth_parameters(data):\n",
    "    first_deriv = np.diff(data, axis=2)\n",
    "    second_deriv = np.diff(first_deriv, axis=2)\n",
    "\n",
    "    activity = np.var(data, axis=2)\n",
    "    mobility = np.sqrt(np.var(first_deriv, axis=2) / activity)\n",
    "    complexity = np.sqrt(np.var(second_deriv, axis=2) / np.var(first_deriv, axis=2)) / mobility\n",
    "\n",
    "    return activity, mobility, complexity\n",
    "\n",
    "# Time-domain feature extraction\n",
    "mean_values = np.mean(EEGsample_normalized, axis=2)\n",
    "std_dev_values = np.std(EEGsample_normalized, axis=2)\n",
    "skewness_values = skew(EEGsample_normalized, axis=2)\n",
    "kurtosis_values = kurtosis(EEGsample_normalized, axis=2)\n",
    "\n",
    "activity, mobility, complexity = hjorth_parameters(EEGsample_normalized)\n",
    "\n",
    "# Summarize the extracted features\n",
    "time_domain_features = {\n",
    "    \"Mean_Values\": mean_values.shape,\n",
    "    \"Standard_Deviation\": std_dev_values.shape,\n",
    "    \"Skewness\": skewness_values.shape,\n",
    "    \"Kurtosis\": kurtosis_values.shape,\n",
    "    \"Activity\": activity.shape,\n",
    "    \"Mobility\": mobility.shape,\n",
    "    \"Complexity\": complexity.shape\n",
    "}\n",
    "\n",
    "time_domain_features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a6b5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import welch\n",
    "\n",
    "# Function to calculate Power Spectral Density (PSD) and Band Power Ratios\n",
    "def calculate_psd_and_band_power(data, fs):\n",
    "    # Define frequency bands\n",
    "    bands = {\n",
    "        'Delta': (1, 4),\n",
    "        'Theta': (4, 8),\n",
    "        'Alpha': (8, 12),\n",
    "        'Beta': (12, 30)\n",
    "    }\n",
    "\n",
    "    # Calculate PSD using Welch's method\n",
    "    freqs, psd = welch(data, fs=fs, axis=2)\n",
    "\n",
    "    # Extracting band power and ratios\n",
    "    band_power = {band: np.trapz(psd[:, :, (freqs >= low) & (freqs <= high)], axis=2)\n",
    "                  for band, (low, high) in bands.items()}\n",
    "\n",
    "    return band_power, freqs, psd\n",
    "\n",
    "# Frequency-domain feature extraction\n",
    "band_power, freqs, psd = calculate_psd_and_band_power(EEGsample_normalized, fs)\n",
    "\n",
    "# Summarize the extracted features\n",
    "frequency_domain_features = {\n",
    "    \"Delta_Band_Power\": band_power['Delta'].shape,\n",
    "    \"Theta_Band_Power\": band_power['Theta'].shape,\n",
    "    \"Alpha_Band_Power\": band_power['Alpha'].shape,\n",
    "    \"Beta_Band_Power\": band_power['Beta'].shape,\n",
    "    \"PSD_Shape\": psd.shape\n",
    "}\n",
    "\n",
    "frequency_domain_features\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bf6f79",
   "metadata": {},
   "source": [
    "# The time-frequency domain feature extraction using Wavelet Transform "
   ]
  },
  {
   "cell_type": "raw",
   "id": "4f378eea",
   "metadata": {},
   "source": [
    "Wavelet Features:\n",
    "The wavelet features have been calculated for each of the 30 channels across all 2022 EEG samples.\n",
    "For each channel in each sample, 12 features have been extracted, combining wavelet energy and entropy across different decomposition levels.\n",
    "Shape of Extracted Features:\n",
    "The shape of the wavelet features array is (2022 samples, 30 channels, 12 features per channel).\n",
    "Summary of Feature Extraction Process:\n",
    "Time-Domain Features: Statistical measures and Hjorth parameters.\n",
    "Frequency-Domain Features: Band power in different EEG frequency bands and Power Spectral Density.\n",
    "Time-Frequency Domain Features: Energy and entropy from Wavelet Transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5190dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "# Function to calculate Wavelet Transform features correctly\n",
    "def calculate_wavelet_features_corrected(data, wavelet_name='db4'):\n",
    "    # List to store the wavelet features\n",
    "    wavelet_features = []\n",
    "\n",
    "    for sample in data:\n",
    "        sample_features = []\n",
    "        for channel in sample:\n",
    "            # Wavelet decomposition\n",
    "            coeffs = pywt.wavedec(channel, wavelet_name, level=5)\n",
    "            # Calculate energy for each level\n",
    "            energy = np.array([np.sum(np.square(coeff)) for coeff in coeffs])\n",
    "            # Calculate entropy for each level\n",
    "            entropy = np.array([-np.sum(coeff * np.log2(np.abs(coeff) + 1e-12)) for coeff in coeffs])\n",
    "            # Combine energy and entropy\n",
    "            sample_features.append(np.concatenate([energy, entropy]))\n",
    "        wavelet_features.append(np.array(sample_features))\n",
    "    \n",
    "    return np.array(wavelet_features)\n",
    "\n",
    "# Recalculate wavelet features for the EEG data\n",
    "wavelet_features_corrected = calculate_wavelet_features_corrected(EEGsample_normalized)\n",
    "\n",
    "# Summarize the extracted features\n",
    "time_frequency_domain_features_corrected = {\n",
    "    \"Wavelet_Features_Shape\": wavelet_features_corrected.shape\n",
    "}\n",
    "\n",
    "time_frequency_domain_features_corrected\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3615c5",
   "metadata": {},
   "source": [
    "# Exploratory data analysis (EDA) of the EEG dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e23436",
   "metadata": {},
   "source": [
    "\n",
    "For the exploratory data analysis (EDA) of the EEG dataset, we'll focus on uncovering patterns and insights from the extracted features. The EDA will be structured as follows:\n",
    "\n",
    "Descriptive Statistics:\n",
    "\n",
    "Analyze the basic statistics (mean, standard deviation, etc.) of the extracted features across different states (alert and drowsy) and subjects.\n",
    "Feature Distribution Analysis:\n",
    "\n",
    "Examine the distributions of key features like band powers and Hjorth parameters for different states and subjects.\n",
    "Use histograms, boxplots, or violin plots for visualization.\n",
    "Correlation Analysis:\n",
    "\n",
    "Assess the correlation between different features to identify any strong relationships or redundancies.\n",
    "State-wise Comparison:\n",
    "\n",
    "Compare the features for alert and drowsy states to see if any features significantly differ between these states.\n",
    "This can be done using statistical tests like t-tests or ANOVA for numerical features.\n",
    "Subject Variability Analysis:\n",
    "\n",
    "Explore how features vary across different subjects to understand inter-subject variability.\n",
    "Investigate if any subject-specific patterns emerge.\n",
    "Time-Frequency Feature Analysis:\n",
    "\n",
    "Analyze wavelet-based features to see how energy and entropy vary across different time-frequency scales and states.\n",
    "Visualization:\n",
    "\n",
    "Create visual representations of the data and features to better understand the underlying patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e66a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Convert features and labels into a DataFrame for easier analysis\n",
    "features_df = pd.DataFrame({\n",
    "    'Subject': subindex.flatten(),\n",
    "    'State': substate.flatten(),\n",
    "    'Delta_Power': band_power['Delta'].mean(axis=1),\n",
    "    'Theta_Power': band_power['Theta'].mean(axis=1),\n",
    "    'Alpha_Power': band_power['Alpha'].mean(axis=1),\n",
    "    'Beta_Power': band_power['Beta'].mean(axis=1),\n",
    "    'Activity': activity.mean(axis=1),\n",
    "    'Mobility': mobility.mean(axis=1),\n",
    "    'Complexity': complexity.mean(axis=1)\n",
    "})\n",
    "\n",
    "# Descriptive statistics\n",
    "desc_stats = features_df.groupby('State').describe()\n",
    "\n",
    "# Distribution analysis: Band Powers and Hjorth Parameters\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, feature in enumerate(['Delta_Power', 'Theta_Power', 'Alpha_Power', 'Beta_Power', 'Activity', 'Mobility', 'Complexity'], 1):\n",
    "    plt.subplot(3, 3, i)\n",
    "    sns.boxplot(x='State', y=feature, data=features_df)\n",
    "    plt.title(feature)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "desc_stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a027dc3a",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis (EDA) Summary:\n",
    "Descriptive Statistics:\n",
    "\n",
    "The dataset includes 1011 samples each for alert (State 0) and drowsy (State 1) states.\n",
    "The mean, standard deviation, and other statistical measures for features such as Delta Power, Theta Power, Alpha Power, Beta Power, Activity, Mobility, and Complexity are provided separately for each state.\n",
    "Distribution Analysis:\n",
    "\n",
    "The boxplots visualize the distribution of key features across the two states.\n",
    "Features like Delta Power, Theta Power, Alpha Power, and Beta Power show variability across the two states.\n",
    "Hjorth Parameters (Activity, Mobility, Complexity) also exhibit differences between alert and drowsy states.\n",
    "Observations:\n",
    "Band Power Features: There are noticeable differences in the power distribution of various frequency bands between alert and drowsy states. This aligns with neuroscientific understanding that different brainwave patterns are associated with different states of consciousness.\n",
    "Hjorth Parameters: These features, which capture the signal's variance, frequency, and frequency variance, also show variations between states."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90309d42",
   "metadata": {},
   "source": [
    "# Correlation Analysis"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c2b975a5",
   "metadata": {},
   "source": [
    "Correlation Analysis Results:\n",
    "The heatmap and correlation matrix reveal several interesting relationships between the features:\n",
    "\n",
    "High Correlations Among Band Powers:\n",
    "\n",
    "There are strong positive correlations among the Delta, Theta, Alpha, and Beta Band Powers. For instance, Delta Power and Alpha Power show a correlation coefficient of 0.87, indicating a high degree of linear relationship.\n",
    "Similarly, Activity shows high correlations with all band power features, with coefficients exceeding 0.84 in most cases.\n",
    "State Correlation:\n",
    "\n",
    "The 'State' feature shows a moderate positive correlation with Alpha Power (0.09) and a negative correlation with Mobility (-0.33).\n",
    "Mobility and Complexity:\n",
    "\n",
    "Mobility and Complexity show a strong negative correlation (-0.69), suggesting that as one increases, the other tends to decrease.\n",
    "Interpretation:\n",
    "The strong correlations among the band power features suggest that these features tend to change together. This could be due to the nature of EEG signals, where changes in brain state (alert vs. drowsy) impact multiple frequency bands simultaneously.\n",
    "The negative correlation between Mobility and Complexity is intriguing and may reflect underlying neurophysiological dynamics.\n",
    "The correlations with the 'State' feature are relatively modest, indicating that no single feature dominantly distinguishes between alert and drowsy states. This suggests the need for a multivariate approach in any predictive modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714d2344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the correlation matrix\n",
    "correlation_matrix = features_df.drop('Subject', axis=1).corr()\n",
    "\n",
    "# Plotting the correlation matrix as a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title(\"Correlation Matrix of EEG Features\")\n",
    "plt.show()\n",
    "\n",
    "correlation_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e60feb3",
   "metadata": {},
   "source": [
    "# State-wise Comparison Using T-Tests"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2985cea6",
   "metadata": {},
   "source": [
    "For the state-wise comparison using statistical testing, we will conduct tests to determine if there are significant differences in the features between the alert and drowsy states. The appropriate test to use here is the independent samples t-test, which compares the means of two independent groups (in this case, the alert and drowsy states) to see if they are statistically different.\n",
    "\n",
    "We'll perform t-tests for key features like band powers and Hjorth parameters. It's important to note that these tests assume the data are normally distributed; however, for simplicity, we'll proceed with the t-tests and interpret the results with this limitation in mind.\n",
    "\n",
    "Let's conduct the t-tests for each feature and interpret the results.\n",
    "\n",
    "State-wise Comparison Using T-Tests:\n",
    "The results of the independent samples t-tests for each feature between the alert (State 0) and drowsy (State 1) states are as follows:\n",
    "\n",
    "Delta Power:\n",
    "\n",
    "T-statistic: -2.77, P-value: 0.0058\n",
    "There is a statistically significant difference in Delta Power between the alert and drowsy states.\n",
    "Theta Power:\n",
    "\n",
    "T-statistic: -2.81, P-value: 0.0050\n",
    "Theta Power also shows a significant difference between the two states.\n",
    "Alpha Power:\n",
    "\n",
    "T-statistic: -3.98, P-value: 0.00007\n",
    "Alpha Power demonstrates a highly significant difference between alert and drowsy states.\n",
    "Beta Power:\n",
    "\n",
    "T-statistic: -1.67, P-value: 0.0941\n",
    "The difference in Beta Power is not statistically significant at a conventional threshold (e.g., p < 0.05).\n",
    "Activity:\n",
    "\n",
    "T-statistic: -2.73, P-value: 0.0065\n",
    "Activity shows a significant difference between the two states.\n",
    "Mobility:\n",
    "\n",
    "T-statistic: 15.66, P-value: 3.21e-52\n",
    "Mobility exhibits a highly significant difference, with a very strong t-statistic value.\n",
    "Complexity:\n",
    "\n",
    "T-statistic: -5.50, P-value: 4.17e-08\n",
    "Complexity also shows a highly significant difference between alert and drowsy states.\n",
    "Interpretation:\n",
    "Significant Features: Delta Power, Theta Power, Alpha Power, Activity, Mobility, and Complexity show significant differences between alert and drowsy states. This suggests that these features are potentially good indicators of the state of drowsiness in drivers.\n",
    "Beta Power: The difference in Beta Power between the states is not statistically significant, indicating that it might not be as effective in differentiating between alert and drowsy states as the other features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b3aef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Function to perform t-test for each feature between alert and drowsy states\n",
    "def perform_t_tests(df, features):\n",
    "    t_test_results = {}\n",
    "    for feature in features:\n",
    "        alert_values = df[df['State'] == 0][feature]\n",
    "        drowsy_values = df[df['State'] == 1][feature]\n",
    "        t_stat, p_value = ttest_ind(alert_values, drowsy_values, equal_var=False)\n",
    "        t_test_results[feature] = {'t_stat': t_stat, 'p_value': p_value}\n",
    "    return t_test_results\n",
    "\n",
    "# Features to perform t-test on\n",
    "features_for_t_test = ['Delta_Power', 'Theta_Power', 'Alpha_Power', 'Beta_Power', 'Activity', 'Mobility', 'Complexity']\n",
    "\n",
    "# Performing the t-tests\n",
    "t_test_results = perform_t_tests(features_df, features_for_t_test)\n",
    "\n",
    "t_test_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9d6fe4",
   "metadata": {},
   "source": [
    "# subject variability analysis"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2cb07d22",
   "metadata": {},
   "source": [
    "We'll focus on the following aspects:\n",
    "\n",
    "Feature Variability Across Subjects:\n",
    "\n",
    "Analyze how each feature (like band powers and Hjorth parameters) varies from one subject to another.\n",
    "Use visualization tools like boxplots to compare the distribution of features across subjects.\n",
    "Comparison Across States for Each Subject:\n",
    "\n",
    "For each subject, compare the feature distributions between the alert and drowsy states.\n",
    "This helps to understand if the patterns observed in the overall dataset hold true at the individual subject level.\n",
    "Identification of Subject-Specific Patterns:\n",
    "\n",
    "Look for any unique patterns or outliers in feature distributions that are specific to certain subjects.\n",
    "\n",
    "\n",
    "Subject Variability Analysis Results:\n",
    "The boxplots illustrate the variability of key EEG features across different subjects:\n",
    "\n",
    "Band Powers (Delta, Theta, Alpha, Beta):\n",
    "\n",
    "There is noticeable variability in band power features across subjects, indicating that each subject's EEG patterns can be quite distinct.\n",
    "Some subjects show higher or lower median values in certain bands, suggesting individual differences in brainwave activities.\n",
    "Hjorth Parameters (Activity, Mobility, Complexity):\n",
    "\n",
    "Similar to band powers, there is a significant inter-subject variability in these parameters.\n",
    "The range of values (as indicated by the length of the boxplots) and the median values vary considerably across subjects.\n",
    "Observations:\n",
    "Inter-Subject Variability: The analysis highlights substantial inter-subject variability in EEG features, which is a common challenge in EEG-based studies. This variability can be due to individual differences in brain structure, cognitive processes, and even factors like electrode placement.\n",
    "Implications for Modeling: The variability emphasizes the need for models that can generalize well across different subjects or, alternatively, the development of personalized models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13867d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of feature variability across subjects\n",
    "plt.figure(figsize=(20, 15))\n",
    "\n",
    "# Selecting a subset of features for visualization\n",
    "features_to_visualize = ['Delta_Power', 'Theta_Power', 'Alpha_Power', 'Beta_Power', 'Activity', 'Mobility', 'Complexity']\n",
    "\n",
    "# Plotting boxplots for each feature across subjects\n",
    "for i, feature in enumerate(features_to_visualize, 1):\n",
    "    plt.subplot(3, 3, i)\n",
    "    sns.boxplot(x='Subject', y=feature, data=features_df)\n",
    "    plt.title(feature)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Note: Due to the large number of subjects, the individual boxplots might be closely packed. The aim is to observe overall trends and variations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb6df23",
   "metadata": {},
   "source": [
    "# Detailed Subject-State Analysis"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a737587f",
   "metadata": {},
   "source": [
    "For the detailed Subject-State Analysis, we will compare the features between the alert and drowsy states for each subject. This analysis helps in understanding whether the changes in EEG features associated with drowsiness are consistent across different individuals. We'll focus on key features like band powers and Hjorth parameters.\n",
    "\n",
    "The approach will be:\n",
    "\n",
    "Compare Features for Each State Within Subjects:\n",
    "\n",
    "Analyze how features like Delta Power, Theta Power, Alpha Power, Beta Power, Activity, Mobility, and Complexity differ between alert and drowsy states within each subject.\n",
    "This can involve visualizing these comparisons using plots for each subject.\n",
    "Identify Consistent Patterns Across Subjects:\n",
    "\n",
    "Look for patterns that are consistent across subjects, such as increases or decreases in certain features when transitioning from alert to drowsy states.\n",
    "Highlight Subject-Specific Variations:\n",
    "\n",
    "Identify any subjects who exhibit unique patterns that differ from the general trend.\n",
    "Let's begin this analysis by visualizing the comparison of key features between alert and drowsy states for each subject.\n",
    "\n",
    "\n",
    "For the detailed Subject-State Analysis, we will compare the features between the alert and drowsy states for each subject. This analysis helps in understanding whether the changes in EEG features associated with drowsiness are consistent across different individuals. We'll focus on key features like band powers and Hjorth parameters.\n",
    "\n",
    "The approach will be:\n",
    "\n",
    "Compare Features for Each State Within Subjects:\n",
    "\n",
    "Analyze how features like Delta Power, Theta Power, Alpha Power, Beta Power, Activity, Mobility, and Complexity differ between alert and drowsy states within each subject.\n",
    "This can involve visualizing these comparisons using plots for each subject.\n",
    "Identify Consistent Patterns Across Subjects:\n",
    "\n",
    "Look for patterns that are consistent across subjects, such as increases or decreases in certain features when transitioning from alert to drowsy states.\n",
    "Highlight Subject-Specific Variations:\n",
    "\n",
    "Identify any subjects who exhibit unique patterns that differ from the general trend.\n",
    "Let's begin this analysis by visualizing the comparison of key features between alert and drowsy states for each subject.\n",
    "\n",
    "Output image\n",
    "Detailed Subject-State Analysis Results:\n",
    "The boxplots provide a comparative view of key EEG features between the alert and drowsy states across different subjects:\n",
    "\n",
    "Variability Across Features and States:\n",
    "\n",
    "The plots show how each feature (Delta, Theta, Alpha, Beta Power, Activity, Mobility, Complexity) varies between the alert and drowsy states for each subject.\n",
    "There are noticeable differences in the distributions of these features between the two states for most subjects.\n",
    "Consistent and Subject-Specific Patterns:\n",
    "\n",
    "In several cases, consistent patterns emerge across subjects, such as differences in band powers or Hjorth parameters between states.\n",
    "However, there are also subject-specific variations. Some subjects show more pronounced differences between states in certain features, while others exhibit less variability.\n",
    "Observations:\n",
    "State-Related Changes: For many subjects, certain features show distinct changes between alert and drowsy states, aligning with the overall trends observed in the dataset.\n",
    "Inter-Subject Variability: The extent and nature of these changes vary across subjects, highlighting the challenge of inter-subject variability in EEG analysis.\n",
    "Implications for Modeling: The analysis underscores the importance of considering subject variability in designing and training predictive models. It may be beneficial to incorporate subject-specific adaptations or to use models that can account for this variability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c990b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of feature comparison between states for each subject\n",
    "plt.figure(figsize=(20, 30))\n",
    "\n",
    "# Looping through each feature for visualization\n",
    "for i, feature in enumerate(features_to_visualize, 1):\n",
    "    plt.subplot(len(features_to_visualize), 1, i)\n",
    "    sns.boxplot(x='Subject', y=feature, hue='State', data=features_df)\n",
    "    plt.title(f\"{feature} Comparison Between Alert and Drowsy States Across Subjects\")\n",
    "    plt.legend(title='State', loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Note: Due to the complexity of the dataset and the number of subjects, these plots provide a high-level overview. Detailed analysis might require focusing on specific subjects or features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac76da9",
   "metadata": {},
   "source": [
    "# Focusing on specific subjects or features "
   ]
  },
  {
   "cell_type": "raw",
   "id": "602092ce",
   "metadata": {},
   "source": [
    "\n",
    "Focusing on specific subjects or features allows for a more detailed and targeted analysis, helping to uncover unique patterns or anomalies that might be obscured in a broader analysis. To proceed, let's select a subset of subjects and features that are of particular interest based on the previous analyses.\n",
    "\n",
    "Approach:\n",
    "Selecting Subjects:\n",
    "\n",
    "Choose subjects who exhibit unique or pronounced differences in their EEG features between alert and drowsy states. This could include subjects with the most significant changes or those with atypical patterns.\n",
    "Selecting Features:\n",
    "\n",
    "Focus on features that showed significant differences in the state-wise comparison or high variability in the subject-wise analysis. For example, features like Alpha Power, Mobility, or Complexity could be interesting to explore in more depth.\n",
    "Detailed Analysis:\n",
    "\n",
    "Conduct a deeper analysis of the selected features for the chosen subjects. This can involve examining the time-series data, comparing statistical distributions, and looking for patterns specific to the alert or drowsy states.\n",
    "Visualization:\n",
    "\n",
    "Use visualizations like line plots or advanced plots (e.g., time-frequency plots) to better understand the dynamics of these features in different states for the selected subjects.\n",
    "Let's select a few subjects and focus on a couple of features for this detailed analysis. I'll choose subjects and features based on the variability and significance observed in the previous steps. We'll then visualize and analyze these features in more depth.\n",
    "\n",
    "Detailed Analysis of Selected Subjects and Features:\n",
    "The line plots provide a comparative view of Alpha Power and Mobility across selected subjects (1, 5, and 11) for both alert and drowsy states.\n",
    "\n",
    "Alpha Power:\n",
    "\n",
    "There are noticeable differences in Alpha Power between the alert and drowsy states for the selected subjects.\n",
    "Subject 1 shows a distinct pattern, where Alpha Power appears higher in the drowsy state compared to the alert state. This pattern is less pronounced in Subjects 5 and 11.\n",
    "Mobility:\n",
    "\n",
    "Mobility also varies between states, but the pattern is more subject-specific.\n",
    "For instance, Subject 11 shows a clear difference in Mobility between states, whereas Subjects 1 and 5 show more overlap.\n",
    "Observations:\n",
    "Inter-Subject Variability: The plots highlight the individual differences in how subjects' EEG features respond to states of alertness and drowsiness. Such variability underscores the challenges in creating generalized models for drowsiness detection.\n",
    "State-Specific Patterns: The selected features show state-specific patterns, albeit with variations in magnitude and clarity across subjects. This indicates that while these features are relevant for distinguishing states, their expression is influenced by individual characteristics.\n",
    "Implications:\n",
    "These insights could inform the development of more personalized approaches in EEG-based drowsiness detection systems.\n",
    "Understanding subject-specific patterns may also be crucial for refining algorithms and improving the accuracy of state classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcd9830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting a subset of subjects for detailed analysis\n",
    "# Choosing subjects who showed significant variability or unique patterns in previous analyses\n",
    "selected_subjects = [1, 5, 11]  # Example subjects, can be adjusted based on specific interests\n",
    "\n",
    "# Focusing on a couple of features for detailed analysis\n",
    "selected_features = ['Alpha_Power', 'Mobility']  # Features with significant differences or high variability\n",
    "\n",
    "# Filtering the data for selected subjects and features\n",
    "filtered_df = features_df[features_df['Subject'].isin(selected_subjects)]\n",
    "\n",
    "# Visualization of the selected features for the selected subjects\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for i, feature in enumerate(selected_features, 1):\n",
    "    plt.subplot(len(selected_features), 1, i)\n",
    "    sns.lineplot(x='Subject', y=feature, hue='State', data=filtered_df, marker='o')\n",
    "    plt.title(f\"{feature} Across Selected Subjects\")\n",
    "    plt.legend(title='State', loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Note: The line plots provide a comparative view of the selected features across the chosen subjects and states.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23da103f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f26dcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f06845b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b79889",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997b0f37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea0eead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18a2c5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebc0f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45391f77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452ba69a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07b5178",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af876e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59153baf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d104da6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00770ca4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397ef9c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f1357c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe73269",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a54c9a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec619066",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3725e7dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40aff1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932b3e02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0987e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f8ea2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1878a394",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354e0a89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5147ae3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1bcafd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a986130c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0981193",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e28630",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659813c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a77a43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ade7140",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01502852",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9082c83d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3450df66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46958d17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea31bdc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abc65f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727bd123",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f0c0d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2923dd84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2074542b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fdc0c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa86d5b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68f6658",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83235364",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612f09e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2f5c0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b93ca7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fe4711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9af1f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7109224e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15638ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ed52bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec9fe3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67677f61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543b3ba5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528c3218",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8d5ab7d",
   "metadata": {},
   "source": [
    "# Visualization of EEG waveforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f34c95",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Selecting all channels for visualization\n",
    "all_channels = list(range(1, 31))\n",
    "\n",
    "# Creating plots\n",
    "fig, axes = plt.subplots(nrows=len(all_channels), ncols=2, figsize=(15, 5 * len(all_channels)))\n",
    "fig.suptitle('EEG Waveforms Comparison: Alert vs Drowsy States', fontsize=16)\n",
    "\n",
    "# Plotting for each channel\n",
    "for i, channel in enumerate(all_channels):\n",
    "    \n",
    "    \n",
    "    # Alert state\n",
    "    axes[i, 0].plot(EEGsamples[substates == 0][:, channel - 1, :].mean(axis=0))\n",
    "    axes[i, 0].set_title(f'Channel {channel} - Alert State')\n",
    "    axes[i, 0].set_xlabel('Time Points')\n",
    "    axes[i, 0].set_ylabel('EEG Signal')\n",
    "    axes[i, 0].grid(True)  # Add grid lines\n",
    "\n",
    "    \n",
    "    # Drowsy state\n",
    "    axes[i, 1].plot(EEGsamples[substates == 1][:, channel - 1, :].mean(axis=0))\n",
    "    axes[i, 1].set_title(f'Channel {channel} - Drowsy State')\n",
    "    axes[i, 1].set_xlabel('Time Points')\n",
    "    axes[i, 1].grid(True)  # Add grid lines\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41fbe63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have the EEGsamples and substates defined\n",
    "\n",
    "# Selecting all channels for visualization\n",
    "all_channels = list(range(1, 31))\n",
    "\n",
    "# Creating plots\n",
    "fig, axes = plt.subplots(nrows=len(all_channels), ncols=1, figsize=(10, 3 * len(all_channels)))\n",
    "fig.suptitle('EEG Waveforms Comparison: Alert vs Drowsy States', fontsize=16)\n",
    "\n",
    "# Plotting for each channel\n",
    "for i, channel in enumerate(all_channels):\n",
    "    # Alert state\n",
    "    alert_mean = EEGsamples[substates == 0][:, channel - 1, :].mean(axis=0)\n",
    "    axes[i].plot(alert_mean, label='Alert', alpha=0.7)\n",
    "\n",
    "    # Drowsy state\n",
    "    drowsy_mean = EEGsamples[substates == 1][:, channel - 1, :].mean(axis=0)\n",
    "    axes[i].plot(drowsy_mean, label='Drowsy', alpha=0.7)\n",
    "\n",
    "    axes[i].set_title(f'Channel {channel}')\n",
    "    axes[i].set_xlabel('Time Points')\n",
    "    axes[i].set_ylabel('EEG Signal')\n",
    "    axes[i].legend()\n",
    "\n",
    "    # Add grid\n",
    "    axes[i].grid(True)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fc3832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot EEG signals for a given sample\n",
    "def plot_eeg_sample(eeg_data, sample_index, title):\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    for i in range(eeg_data.shape[1]):\n",
    "        plt.plot(eeg_data[sample_index, i, :], label=f'Channel {i+1}')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Time Points')\n",
    "    plt.ylabel('EEG Signal Amplitude')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Find the index of the first occurrence of 0 (alert state)\n",
    "sample_alert_index = list(substate).index(0)\n",
    "\n",
    "# Find the index of the first occurrence of 1 (drowsy state)\n",
    "sample_drowsy_index = list(substate).index(1)\n",
    "\n",
    "# Plot EEG samples for alert and drowsy states\n",
    "plot_eeg_sample(eeg_samples, sample_alert_index, 'EEG Sample - Alert State')\n",
    "plot_eeg_sample(eeg_samples, sample_drowsy_index, 'EEG Sample - Drowsy State')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fd9eb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795f26b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bdea03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c3ef60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc36109",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e55e299",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "num_subjects = 11  # Assuming you have 11 subjects\n",
    "num_channels = 30  # Assuming you have 30 channels\n",
    "\n",
    "for subject in range(num_subjects):\n",
    "    # Create a figure for each subject\n",
    "    fig, axes = plt.subplots(nrows=num_channels, ncols=1, figsize=(10, 3 * num_channels))\n",
    "    fig.suptitle(f'EEG Data for Subject {subject + 1}', fontsize=16)\n",
    "\n",
    "    for channel in range(num_channels):\n",
    "        # Extract data for the current channel and subject\n",
    "        channel_data = EEGsamples[subject, channel, :]\n",
    "\n",
    "        # Plotting\n",
    "        axes[channel].plot(channel_data, label=f'Channel {channel + 1}')\n",
    "        axes[channel].set_title(f'Channel {channel + 1}')\n",
    "        axes[channel].set_xlabel('Time Points')\n",
    "        axes[channel].set_ylabel('EEG Signal')\n",
    "        axes[channel].legend()\n",
    "        axes[channel].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c01843d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d922feaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e6286a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e8bedd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b70ab7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f6d4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Summary statistics for the entire EEGsamples dataset\n",
    "mean_value = np.mean(EEGsamples)\n",
    "std_value = np.std(EEGsamples)\n",
    "min_value = np.min(EEGsamples)\n",
    "max_value = np.max(EEGsamples)\n",
    "\n",
    "print(f\"Overall Mean: {mean_value}, Std: {std_value}, Min: {min_value}, Max: {max_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4136f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example: Subject 1, Channel 1\n",
    "subject = 0\n",
    "channel = 0\n",
    "plt.plot(EEGsamples[subject, channel, :])\n",
    "plt.title(f'EEG Data for Subject {subject+1}, Channel {channel+1}')\n",
    "plt.xlabel('Time Points')\n",
    "plt.ylabel('EEG Signal')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efff428",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Display data for Subject 1 across all channels and first 10 time points\n",
    "data_slice = EEGsamples[subject, :, :10]\n",
    "df = pd.DataFrame(data_slice)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ee37df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the value for Subject 1, Channel 1, at the first time point\n",
    "print(\"Specific value:\", EEGsamples[subject, channel, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a32384b",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.kaggle.com/code/tenebris97/emotions-eeg-lstm-gru-dnn-98-44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd5c3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.kaggle.com/code/tenebris97/gridsearch-shap-lstm-dnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b420e607",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070293cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c861fa26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61742455",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
